# Amundi GEM Regulatory Intelligence RAG

Plateforme d'intelligence artificielle pour la veille r√©glementaire europ√©enne avec recherche s√©mantique (RAG).

## üéØ Vue d'ensemble

Ce projet collecte, indexe et permet d'interroger en langage naturel les publications de 8 autorit√©s financi√®res europ√©ennes via :
- **Web Scraping** automatis√©
- **Base MySQL** pour le stockage structur√©
- **ChromaDB** pour la recherche vectorielle
- **OpenAI Embeddings** pour la compr√©hension s√©mantique

---

## üèóÔ∏è Architecture

```
Scraping ‚Üí MySQL ‚Üí Vectorisation ‚Üí ChromaDB ‚Üí Recherche RAG
```

### Stack Technique
- **Python 3.13**
- **MySQL 8.0** (Docker)
- **ChromaDB 1.3.7** (local)
- **OpenAI API** (text-embedding-3-small)
- **Selenium** + BeautifulSoup4

---

## üåç Sources Surveill√©es

| Source | Pays/Zone | Langue | Articles |
|--------|-----------|--------|----------|
| AFG | üá´üá∑ France | FR | 10 |
| AFM | üá≥üá± Pays-Bas | EN | 5 |
| ALFI | üá±üá∫ Luxembourg | EN | 5 |
| AMF | üá´üá∑ France | FR | 5 |
| CBI | üáÆüá™ Irlande | EN | 5 |
| CSSF | üá±üá∫ Luxembourg | FR | 5 |
| ESMA | üá™üá∫ Europe | EN | 5 |
| FINMA | üá®üá≠ Suisse | EN | 5 |

---

## üìÇ Structure du Projet

```
AmundiGemScrapper/
‚îú‚îÄ‚îÄ config/                    # Configuration centralis√©e
‚îÇ   ‚îú‚îÄ‚îÄ database.py           # Config MySQL
‚îÇ   ‚îú‚îÄ‚îÄ settings.py           # Settings g√©n√©raux
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py         # Config OpenAI
‚îÇ
‚îú‚îÄ‚îÄ src/                       # Code source
‚îÇ   ‚îú‚îÄ‚îÄ common/               # Utilitaires
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ driver_setup.py
‚îÇ   ‚îú‚îÄ‚îÄ database/             # Gestion BDD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ manager.py
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/           # Chunking + OpenAI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunker.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai_client.py
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/          # ChromaDB
‚îÇ       ‚îî‚îÄ‚îÄ chroma_manager.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                   # Scripts d'administration
‚îÇ   ‚îú‚îÄ‚îÄ run_scraping.py       # Scraping des sources
‚îÇ   ‚îú‚îÄ‚îÄ run_ingestion.py      # JSON ‚Üí MySQL
‚îÇ   ‚îú‚îÄ‚îÄ run_vectorization.py  # MySQL ‚Üí ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ search_rag.py         # Recherche RAG
‚îÇ   ‚îî‚îÄ‚îÄ explore_chroma.py     # Explorer ChromaDB
‚îÇ
‚îú‚îÄ‚îÄ scrapers/                  # Modules de scraping
‚îÇ   ‚îî‚îÄ‚îÄ [afg, afm, alfi, ...]
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Donn√©es g√©n√©r√©es
‚îÇ   ‚îú‚îÄ‚îÄ json/                 # JSON des scrapers
‚îÇ   ‚îî‚îÄ‚îÄ chroma/               # Base vectorielle
‚îÇ
‚îî‚îÄ‚îÄ docker-compose.yml         # MySQL + PHPMyAdmin
```

---

## üöÄ Installation

### 1. Pr√©requis
```bash
# Python 3.10+
python --version

# Docker Desktop (pour MySQL)
docker --version

# Google Chrome (pour Selenium)
```

### 2. Installation
```bash
# Cloner le repo
git clone [url]
cd AmundiGemScrapper

# Environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou : venv\Scripts\activate  # Windows

# D√©pendances
pip install -r requirements.txt
```

### 3. Configuration

**MySQL (Docker)**
```bash
docker-compose up -d
```

**Variables d'environnement**
```bash
# Cr√©er un fichier .env √† la racine
echo "OPENAI_API_KEY=sk-..." > .env
```

**Initialiser la base**
```bash
# La base est cr√©√©e automatiquement au premier run
# Ou manuellement via PHPMyAdmin : http://localhost:8080
```

---

## üìã Utilisation

### Pipeline Complet

```bash
# 1. Scraper les sources (g√©n√®re les JSON)
python scripts/run_scraping.py

# 2. Ing√©rer les JSON dans MySQL
python scripts/run_ingestion.py

# 3. Vectoriser les articles (MySQL ‚Üí ChromaDB)
python scripts/run_vectorization.py

# 4. Rechercher via RAG
python scripts/search_rag.py "What is ESMA's position on crypto?"
```

### Commandes Utiles

```bash
# Recherche simple
python scripts/search_rag.py "r√©glementation AMF cloud"

# Recherche avec filtre par source
python scripts/search_rag.py "Luxembourg regulations" --source CSSF

# Recherche avec plus de r√©sultats
python scripts/search_rag.py "MiFID II" --n 10

# Explorer ChromaDB
python scripts/explore_chroma.py
```

---

## üí∞ Co√ªts OpenAI

**Vectorisation initiale (45 articles) :**
- ~30K tokens
- Co√ªt : **$0.0006** (~0.06 centimes)

**Recherche :**
- ~100 tokens par requ√™te
- Co√ªt : **$0.000002** par recherche (gratuit)

**Total mensuel estim√© :** < $1

---

## üîß Maintenance

### Ajouter de nouvelles sources
1. Cr√©er `scrapers/nouvelle_source/`
2. Impl√©menter `get_list.py` et `get_content.py`
3. Ajouter dans `config/settings.py` ‚Üí `SOURCES_CONFIG`
4. Relancer le pipeline

### R√©indexer ChromaDB
```bash
# Supprimer et recr√©er
python scripts/run_vectorization.py
# R√©pondre 'y' quand demand√©
```


---

## üéØ Roadmap

- [x] Scraping des 8 sources
- [x] Stockage MySQL
- [x] Vectorisation ChromaDB
- [x] Recherche RAG
- [ ] Interface Streamlit
- [ ] G√©n√©ration de r√©ponses (GPT-4)
- [ ] Scraping incr√©mental (nouveaux articles)
- [ ] Multi-tenancy (plusieurs utilisateurs)
- [ ] API REST

---

## üìä Statistiques du Projet

- **45 articles** collect√©s
- **53 chunks** vectoris√©s
- **8 sources** r√©glementaires
- **2 langues** (FR/EN)
- **Co√ªt total** : $0.0006

---

## üêõ D√©pannage

### MySQL inaccessible
```bash
docker ps  # V√©rifier que le conteneur tourne
docker-compose up -d
```

### ChromaDB vide apr√®s vectorisation
```bash
# V√©rifier que les fichiers existent
ls -la data/chroma/

# Relancer la vectorisation
python scripts/run_vectorization.py
```

### Cl√© OpenAI invalide
```bash
# V√©rifier le .env
cat .env

# Exporter manuellement
export OPENAI_API_KEY="sk-..."
```
